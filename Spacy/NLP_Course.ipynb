{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from IPython.display import SVG, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução ao Spacy\n",
    "\n",
    "Diferente do curso original, aqui tentarei utilizar exemplos e linguagem em português para comparar a qualidade dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível interagir com os tokens e identificar o seu tipo (número, pontuação, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá \t=> Is punct: False\t| number: False\t| stop: False\n",
      ", \t=> Is punct: True\t| number: False\t| stop: False\n",
      "mundo \t=> Is punct: False\t| number: False\t| stop: False\n",
      "! \t=> Is punct: True\t| number: False\t| stop: False\n",
      "Um \t=> Is punct: False\t| number: True\t| stop: True\n",
      ", \t=> Is punct: True\t| number: False\t| stop: False\n",
      "dois \t=> Is punct: False\t| number: True\t| stop: True\n",
      "e \t=> Is punct: False\t| number: False\t| stop: True\n",
      "três \t=> Is punct: False\t| number: True\t| stop: True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Olá, mundo! Um, dois e três')\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text} \\t=> Is punct: {token.is_punct}\\t| number: {token.like_num}\\t| stop: {token.is_stop}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Identifica tokens que se referem a números mesmo que esteja escrito por extenso\n",
    "* Identifica stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ela PRON nsubj comeu\n",
      "comeu VERB ROOT comeu\n",
      "a DET det pizza\n",
      "pizza NOUN obj comeu\n"
     ]
    }
   ],
   "source": [
    "text = \"Ela comeu a pizza\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"nsubj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifica as partes da fala (POS). É possível identificar o tipo de palavra (verbo, substantivo, etc) com um vocabulário em português previamente treinado. Estou usando aqui o modelo small, mas existem outros modelos maiores que podem ser utilizados, como o Large (mesmo nome com final `lg` ao invés de `sm`). A alteração do modelo pode apresentar algumas alterações nos resultados de POS. O significado de cada tag de POS pode ser encontrado [aqui](https://universaldependencies.org/u/pos/DET.html). Além disso, basta executar o comando `spacy.explain('ADJ')` para obter a explicação de cada tag.\n",
    "\n",
    "Além disso, as propriedades `dep_` e `head` trazem as dependências entre as palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venha\tVERB\tROOT\tVenha\n",
      "ver\tVERB\txcomp\tVenha\n",
      "as\tDET\tdet\tpromoções\n",
      "promoções\tNOUN\tobj\tver\n",
      "de\tADP\tcase\tcelulares\n",
      "celulares\tNOUN\tnmod\tpromoções\n",
      "samsung\tPROPN\tappos\tpromoções\n",
      "na\tADP\tcase\tamericanas\n",
      "americanas\tNOUN\tobl\tver\n",
      "nessa\tADP\tcase\tblack\n",
      "black\tPROPN\tobl\tver\n",
      "friday\tPROPN\tflat:name\tblack\n",
      "cerveja\tADJ\tamod\tblack\n",
      ".\tPUNCT\tpunct\tVenha\n",
      "Apple\tPROPN\tnsubj\tpensando\n",
      "está\tAUX\taux\tpensando\n",
      "pensando\tVERB\tROOT\tpensando\n",
      "em\tSCONJ\tmark\tcomprar\n",
      "comprar\tVERB\txcomp\tpensando\n",
      "empresa\tNOUN\tobj\tcomprar\n",
      "do\tADP\tcase\tBrasil\n",
      "Brasil\tPROPN\tnmod\tempresa\n",
      "por\tADP\tcase\tR$\n",
      "R$\tSYM\tobl\tcomprar\n",
      "1\tNUM\tnummod\tR$\n",
      "bilhão\tNUM\tflat\t1\n",
      ".\tPUNCT\tpunct\tpensando\n",
      "Apple\tPROPN\tnsubj\tquerendo\n",
      "está\tAUX\taux\tquerendo\n",
      "querendo\tVERB\tROOT\tquerendo\n",
      "comprar\tVERB\txcomp\tquerendo\n",
      "uma\tDET\tdet\tstartup\n",
      "startup\tNOUN\tobj\tcomprar\n",
      "do\tADP\tcase\tReino\n",
      "Reino\tPROPN\tnmod\tstartup\n",
      "Unido\tPROPN\tflat:name\tReino\n",
      "por\tADP\tcase\t100\n",
      "100\tNUM\tobl\tcomprar\n",
      "milhões\tNUM\tflat\t100\n",
      "de\tADP\tcase\tdólares\n",
      "dólares\tNOUN\tnmod\t100\n",
      ".\tPUNCT\tpunct\tquerendo\n",
      "\n",
      "----------------------\n",
      "\n",
      "Venha LOC\n",
      "Apple ORG\n",
      "Brasil LOC\n",
      "Apple ORG\n",
      "Reino Unido LOC\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_lg')\n",
    "text = \"Venha ver as promoções de celulares samsung na americanas nessa black friday cerveja. Apple está pensando em comprar empresa do Brasil por R$ 1 bilhão. Apple está querendo comprar uma startup do Reino Unido por 100 milhões de dólares.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text}\\t{token.pos_}\\t{token.dep_}\\t{token.head.text}')\n",
    "\n",
    "print('\\n----------------------\\n')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note acima que a detecção de entidades para português é bastante incompleta. Especialmente se comparada com a detecção em inglês abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\tPROPN\tnsubj\tlooking\n",
      "is\tAUX\taux\tlooking\n",
      "looking\tVERB\tROOT\tlooking\n",
      "at\tADP\tprep\tlooking\n",
      "buying\tVERB\tpcomp\tat\n",
      "U.K.\tPROPN\tdobj\tbuying\n",
      "startup\tNOUN\tdep\tlooking\n",
      "for\tADP\tprep\tstartup\n",
      "$\tSYM\tquantmod\tbillion\n",
      "1\tNUM\tcompound\tbillion\n",
      "billion\tNUM\tpobj\tfor\n",
      "and\tCCONJ\tcc\tstartup\n",
      "samsung\tPROPN\tnsubj\twaiting\n",
      "is\tAUX\taux\twaiting\n",
      "waiting\tVERB\tconj\tstartup\n",
      "to\tPART\taux\tsee\n",
      "see\tVERB\txcomp\twaiting\n",
      "what\tPRON\tnsubj\thappens\n",
      "happens\tVERB\tccomp\tsee\n",
      "\n",
      "----------------------\n",
      "\n",
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n",
      "samsung ORG\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion and samsung is waiting to see what happens\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(f'{token.text}\\t{token.pos_}\\t{token.dep_}\\t{token.head.text}')\n",
    "\n",
    "print('\\n----------------------\\n')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma coisa a se estudar é a possibilidade de incluir entidades dentro da busca. Por exemplo, se eu quiser buscar por um verbo que esteja relacionado a uma entidade específica, como \"comprar\" e \"casa\", eu poderia buscar por `VERB` e `casa` e verificar se o verbo está relacionado à entidade `casa`. Além disso, [essa issue](https://github.com/explosion/spaCy/discussions/10232) parece indicar que é possível adicionar até mesmo padrões, como a identificação de um CPF, por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando as dependências\n",
    "\n",
    "A visualização abaixo é para entender um pouco melhor como a biblioteca entende as relações entre as palavras. Está sendo utilizado o modelo `small`, mas é possível utilizar o `large` para obter resultados mais precisos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"16d5c09bb2f44a3fbaa5d35b35a55f7c-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Venha</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">conhecer</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">as</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">nossas</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">promoções</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">celulares</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">samsung</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">para</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">este</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">natal.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M215.0,266.5 L223.0,254.5 207.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,266.5 L758.0,254.5 742.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-6\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16d5c09bb2f44a3fbaa5d35b35a55f7c-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "text = \"Venha conhecer as nossas promoções de celulares samsung para este natal.\"\n",
    "doc = nlp(text)\n",
    "    \n",
    "def showSVG(s):\n",
    "  display(SVG(s))\n",
    "\n",
    "graph01 = displacy.render(doc)\n",
    "showSVG(graph01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based matching\n",
    "\n",
    "Isso pode ser muito interessante para melhorar a busca do taggeamento dependendo de como ela for ser aplicada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_lg')\n",
    "text = \"Venha conhecer as nossas promoções de celulares samsung para este natal.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung ORG\n",
      "this Christmas DATE\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = \"Come and discover our Samsung cell phone promotions for this Christmas.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note acima que nenhuma entidade foi reconhecida mesmo com o vocabulário de português maior. Por outro lado veja como a mesma frase traduzida para inglês é reconhecida com o vocabulário `small` do inglês. O matching por regras ajudaria a melhorar a identificação, além de poder filtrar por palavras que têm mais de um significado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samsung \n",
      "moto g \n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('pt_core_news_lg')\n",
    "text = \"Venha conhecer as nossas promoções de celulares samsung e moto g para este natal.\"\n",
    "\n",
    "pattern_samsung = [{\"TEXT\": \"samsung\"}]\n",
    "pattern_motog = [{\"TEXT\": \"moto\"}, {\"TEXT\": \"g\"}]\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"SAMSUNG\", [pattern_samsung])\n",
    "matcher.add(\"MOTOG\", [pattern_motog])\n",
    "\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:    \n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda assim, note que não foi identificado diretamente um novo objeto, mas apenas um padrão que utiliza da inteligência dos objetos, como no exemplo abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought a smartphone\n",
      "buying apps\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "pattern = [\n",
    "    {\"LEMMA\": \"buy\"},\n",
    "    {\"POS\": \"DET\", \"OP\": \"?\"},  # optional: match 0 or 1 times\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"BUY\", [pattern])\n",
    "\n",
    "doc = nlp(\"I bought a smartphone. Now I'm buying apps.\")\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:    \n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima é possível perceber que o `matcher` identificou o padrão de que o verbo `comprar` está relacionado com o objeto `casa`. Isso pode ser muito útil para identificar padrões de busca. Abaixo podemos ver que é possível até mesmo fazer combinações semelhantes a RegEx mas de forma muito mais simples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows 7\n",
      "Windows 10\n",
      "Windows 11\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_lg')\n",
    "pattern = [\n",
    "    {\"TEXT\": \"Windows\"},\n",
    "    {\"IS_DIGIT\": True}\n",
    "]\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"WINDOWS\", [pattern])\n",
    "\n",
    "doc = nlp(\"As melhores versões do Windows foram: Windows 7, Windows 10 e Windows 11\")\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:    \n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que apenas os Windows acompanhados de um dígito foram encontrados. A palavra sozinha não fez o match com a regra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded Fortnite\n",
      "downloading Minecraft\n",
      "download Winzip\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"i downloaded Fortnite on my laptop and can't open the game at all. Help? \"\n",
    "    \"so when I was downloading Minecraft, I got the Windows version where it \"\n",
    "    \"is the '.zip' folder and I used the default program to unpack it... do \"\n",
    "    \"I also need to download Winzip?\"\n",
    ")\n",
    "\n",
    "pattern = [{\"LEMMA\": \"download\"}, {\"POS\": \"PROPN\"}]\n",
    "\n",
    "matcher.add(\"DOWNLOAD_THINGS_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:    \n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima, agora em inglês, apenas as palavras com a raíz \"download\" seguidas de nome próprio. Abaixo todos os nomes próprios identificados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samsung\n",
      "motorola\n",
      "electrolux\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_lg')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"aqui na americanas você tem as melhores promoções de celulares samsung e motorola, além das lavadores consul e electrolux\"\n",
    ")\n",
    "\n",
    "pattern = [{\"POS\": \"PROPN\"}]\n",
    "\n",
    "matcher.add(\"PROPN_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:    \n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A identificação dos nomes próprios em português não é perfeita, mas poderia ser usada para identificar possíveis tags não encontradas pelo taggeamento cadastrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched span: Golden Retriever\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "pattern = nlp(\"Golden Retriever\")\n",
    "matcher.add(\"DOG\", [pattern])\n",
    "doc = nlp(\"Eu tenho um Golden Retriever\")\n",
    "\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matcher(doc):\n",
    "    # Get the matched span\n",
    "    span = doc[start:end]\n",
    "    print(\"Matched span:\", span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima vemos que é possível também fazer um Matcher para frases inteiras. O código abaixo de exemplo da documentação é um uso interessante:\n",
    "\n",
    "```python\t\n",
    "import json\n",
    "import spacy\n",
    "\n",
    "with open(\"exercises/en/countries.json\", encoding=\"utf8\") as f:\n",
    "    COUNTRIES = json.loads(f.read())\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"Czech Republic may help Slovakia protect its airspace\")\n",
    "\n",
    "# Import the PhraseMatcher and initialize it\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "# Create pattern Doc objects and add them to the matcher\n",
    "# This is the faster version of: [nlp(country) for country in COUNTRIES]\n",
    "patterns = list(nlp.pipe(COUNTRIES))\n",
    "matcher.add(\"COUNTRY\", patterns)\n",
    "\n",
    "# Call the matcher on the test document and print the result\n",
    "matches = matcher(doc)\n",
    "print([doc[start:end] for match_id, start, end in matches])\n",
    "```\n",
    "\n",
    "Uma lista de tokens pré definidos (nomes dos países) é informada e o match é feito diretamente por essa lista. Isso é basicamente o que fazemos hoje. É necessário apenas estudar se o desempenho do que o spacy faz é melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adicionando novas entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motorola ORG\n",
      "samsung ORG\n",
      "motorola ORG\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "nlp = spacy.load('pt_core_news_lg')\n",
    "\n",
    "doc = nlp(\n",
    "    \"aqui na americanas você tem as melhores promoções de celulares samsung e motorola, além das lavadores consul e electrolux\"\n",
    ")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "span = Span(doc, 10, 11, label=\"ORG\")\n",
    "doc.ents = list(doc.ents) + [span]\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima é adicionado via um documento. Como adicionar para o vocabulário inteiro? Vamos começar criando uma lista de marcas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = [\n",
    "    \"samsung\",\n",
    "    \"motorola\",\n",
    "    \"fruki\",\n",
    "    \"electrolux\",\n",
    "    \"consul\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Promoção lojas americanas com celulares samsung e motorola, além das lavadores consul e electrolux. Venha, estamos esperando você com uma fruki gelada!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motorola ORG\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_lg')\n",
    "\n",
    "doc = nlp(\n",
    "    \"aqui na americanas você tem as melhores promoções de celulares samsung e motorola, além das lavadores consul e electrolux\"\n",
    ")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima vemos que apenas a entidade motorola foi identificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'morphologizer', 'parser', 'lemmatizer', 'attribute_ruler', 'brand_component', 'ner']\n",
      "[('samsung', 'ORG'), ('motorola', 'ORG'), ('consul', 'ORG'), ('electrolux', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "from spacy.language import Language\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "brand_patterns = list(nlp.pipe(brands))\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher.add(\"BRANDS\", brand_patterns)\n",
    "\n",
    "@Language.component(\"brand_component\")\n",
    "def animal_component_function(doc):\n",
    "    # Apply the matcher to the doc\n",
    "    matches = matcher(doc)\n",
    "    # Create a Span for each match and assign the label \"ANIMAL\"\n",
    "    spans = [Span(doc, start, end, label=\"ORG\") for match_id, start, end in matches]\n",
    "    # Overwrite the doc.ents with the matched spans\n",
    "    doc.ents = spans\n",
    "    return doc\n",
    "\n",
    "if \"brand_component\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"brand_component\", before=\"ner\")\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# Process the text and print the text and label for the doc.ents\n",
    "doc = nlp(\n",
    "    \"aqui na americanas você tem as melhores promoções de celulares samsung e motorola, além das lavadores consul e electrolux\"\n",
    ")\n",
    "\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O problema aqui continua que as entidades estão sendo adicionadas não via vocabulário, mas dinamicamente na execução do pipeline de cada documento. Da forma que está já seria útil para o taggeamento hoje, mas não o suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similaridade\n",
    "\n",
    "A similaridade nessa biblioteca é calculada usando Word2Vec em vocabulário já treinado. Utiliza a distância de cosseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6336954300310972\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"Eu comprei um smartphone da Samsung\")\n",
    "doc2 = nlp(\"Ela ganhou um celular da LG\")\n",
    "print(doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo é possível ver como obter o vetor de uma palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96909   -1.8741    -1.6277     1.4424    -0.81577   -1.8003\n",
      " -0.69867   -3.8572     2.1692     0.36282    0.8312    -0.72865\n",
      " -1.8473    -3.1222    -0.98182    0.048301   1.686     -1.0379\n",
      " -0.608     -0.65527    1.5713     1.8352     1.3512    -0.50214\n",
      " -2.403     -1.1599    -0.32929    0.81169   -1.381      2.3942\n",
      " -0.52012    2.195     -2.0804     0.77829   -3.1261     0.14672\n",
      " -1.567      2.106      0.5394    -2.3987     0.39329   -0.9931\n",
      "  0.10342    0.41437    0.073363   1.4713    -1.7604    -0.75015\n",
      " -2.8503    -2.5687     0.85283   -0.14295   -0.66235    0.45273\n",
      "  0.29417   -0.38988    2.6156    -1.0853    -1.6852    -0.05728\n",
      "  0.67298   -1.293     -1.57       0.50339   -2.5344    -2.0501\n",
      " -0.52929   -0.34608   -0.67849    0.11726    2.0476     0.30721\n",
      " -2.714     -0.15327   -1.1189     0.65284    3.0089     1.8972\n",
      " -0.13324    0.59238    0.57586   -3.7116     1.226      1.3121\n",
      " -0.98548    1.0672     0.66809   -0.45836   -0.09541   -2.0687\n",
      "  1.3946     0.33464    0.63427   -0.50086    0.54366   -1.6004\n",
      " -2.2626     0.63939    2.6503     1.3294     0.020195   1.7278\n",
      " -0.13575   -0.52031    0.63673    0.58329   -2.9157    -2.0656\n",
      " -1.561      1.7549     1.088     -0.74638    0.31268    0.64205\n",
      " -1.2214    -0.25861    0.58881    2.2709     0.88443   -1.1767\n",
      "  1.213     -0.85539   -2.267     -0.19636   -1.4997    -2.2711\n",
      " -0.81926    2.4159     0.061102  -0.66588   -0.80645   -1.193\n",
      " -0.44768    0.52223    1.6606     0.92397    0.49792   -0.17894\n",
      "  0.32661    0.21827   -0.50882   -2.0273    -1.4134    -0.85276\n",
      "  1.0144    -0.088501   1.4667     0.57562    2.3252    -0.89166\n",
      " -2.3871     2.0462    -1.0221    -2.0248    -0.81316    1.3467\n",
      " -0.17932    1.308     -2.5183    -0.36288    0.92608    0.4826\n",
      " -0.12909    0.52645   -0.6529    -3.4187    -0.89038   -1.7495\n",
      " -0.35442    0.83941   -1.766      0.6541     0.40159   -1.56\n",
      "  1.9434    -0.91918    0.93428   -3.2881    -1.5687    -0.45684\n",
      "  0.10013   -0.34212    1.4186     0.18627    1.8472    -0.74116\n",
      " -1.374     -0.19876    3.3233     0.7209     1.1487     0.83379\n",
      "  1.3738     1.117     -0.27457   -0.8359    -0.66958   -2.3828\n",
      "  0.64049   -1.5196     1.5211     0.4409    -1.6113    -2.9177\n",
      " -1.9829    -3.2708    -0.60694   -1.1833    -1.3626    -0.58394\n",
      "  0.90951   -0.060975  -0.91615   -0.6334    -4.0072     2.5841\n",
      "  3.6331     0.39931    2.9081     1.5607     0.24819    1.305\n",
      " -0.83777   -1.5775     0.83785   -1.3485     0.92616   -1.6108\n",
      "  1.0212     1.1844     2.0276    -5.2766     1.7291     0.57135\n",
      "  0.13687   -0.6682    -1.3839     0.6869     1.4056     2.4846\n",
      " -1.1883    -3.049      3.1617     1.7542     0.32821    0.14846\n",
      " -2.7883    -0.35733    1.3673    -2.2468    -0.053886   0.63828\n",
      " -0.2208     0.27438    2.2926    -1.4795     0.73915    0.81212\n",
      " -1.5994     0.020847   1.2431     0.32964    2.3946    -1.2561\n",
      "  0.51422   -0.9863     1.1725    -0.72963   -1.388     -2.5489\n",
      "  3.1158     0.85503    1.444      1.5742    -2.4145     1.6361\n",
      " -1.2361     0.11081    1.7823     3.0202     0.65633    1.2706\n",
      " -2.0692     0.767     -1.2224     0.41966   -0.0093124  4.2627\n",
      " -1.9323    -1.9803     3.0922    -0.80315    2.7851    -1.2717\n",
      "  0.86573   -1.2298     2.1343     1.2355    -2.6287     0.05654  ]\n"
     ]
    }
   ],
   "source": [
    "comprei_vector = doc1[1].vector\n",
    "print(comprei_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma é possível obter o vetor de uma frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82877076, -1.4959415 , -0.01407002,  0.50191945, -1.5201298 ,\n",
       "       -2.2141569 , -1.9054449 , -1.3089108 , -0.9012207 , -0.609249  ,\n",
       "        1.409032  , -0.6197735 ,  0.29524034, -2.2386827 , -1.0073334 ,\n",
       "        0.10729835,  2.5295959 ,  0.20271178, -0.11834935,  1.7934837 ,\n",
       "       -1.4205139 ,  1.2539212 ,  0.18040785,  1.5367905 , -0.71002257,\n",
       "        1.6561524 ,  0.7574853 ,  0.20762756, -1.140725  , -0.0794815 ,\n",
       "       -0.6337527 ,  0.599849  , -0.9800525 , -0.9954756 ,  0.08243648,\n",
       "       -0.89043844, -0.9970745 , -0.18366098,  0.32128188,  0.57742554,\n",
       "        0.23275337,  0.44352174, -0.5531765 , -0.8138048 ,  0.514523  ,\n",
       "       -0.621946  , -1.7735662 ,  0.00781301,  1.1821475 , -0.6922964 ,\n",
       "       -1.0185323 , -1.6059405 , -1.5012765 , -0.3584405 , -0.04261879,\n",
       "        0.23985079,  1.0476487 , -1.5052786 ,  0.2574795 ,  1.338814  ,\n",
       "        0.8240164 ,  0.75161153,  0.91135967,  1.9343933 , -0.19888262,\n",
       "        1.2405589 , -0.8107554 ,  0.88141143, -0.64680547, -0.30430394,\n",
       "       -0.13769498, -0.33755454,  0.29709822,  1.239206  , -0.7147482 ,\n",
       "        0.8278638 ,  0.60423726,  1.7803919 ,  0.63790363,  0.51718444,\n",
       "        1.510688  ,  0.67481554,  1.6293478 , -0.2570565 , -0.97354734,\n",
       "       -0.01156489, -0.6769174 , -0.67787397,  1.8806204 , -1.3414689 ,\n",
       "        1.0467988 ,  1.4155114 ,  0.76161045, -0.2936665 , -0.34646448,\n",
       "       -0.72195995,  1.1313021 ,  1.5928218 , -0.21632056,  0.23840168,\n",
       "        0.43625197,  0.4545321 , -0.13790603,  0.8081583 ,  0.33337244,\n",
       "       -0.5800133 , -2.148916  , -0.343993  ,  0.38428426, -0.0860187 ,\n",
       "        0.79235154,  0.12682196,  0.06861098, -0.45910925, -1.4115032 ,\n",
       "       -0.8799609 ,  0.35384   , -1.1425856 ,  0.7873615 ,  2.2367618 ,\n",
       "        2.1116738 , -1.4022064 , -1.3451574 , -0.4543653 ,  1.5767369 ,\n",
       "        0.92267734,  0.435254  ,  1.0817994 ,  0.35478702,  0.54763806,\n",
       "        2.036348  ,  0.9913303 ,  1.4156533 ,  0.63360345,  0.71135247,\n",
       "        0.747919  ,  0.35844445, -2.1932728 , -0.28899652,  0.658371  ,\n",
       "       -1.5306604 ,  0.25337547, -1.2762496 , -2.1918168 , -2.043613  ,\n",
       "       -0.5675472 ,  0.6384385 , -0.0493735 , -0.994943  , -0.7557741 ,\n",
       "       -1.091596  , -0.43153733, -0.50357646, -1.1138531 ,  0.15512867,\n",
       "       -0.99284065, -1.4871869 , -0.45056   , -0.64502853, -1.3692795 ,\n",
       "        0.14837399, -0.05923302, -0.5994094 ,  1.0555995 ,  0.35867006,\n",
       "        1.061207  , -0.513428  , -2.11243   ,  0.27496296, -0.6536337 ,\n",
       "        0.09194309,  0.487924  ,  1.259787  ,  0.6230859 ,  0.19783545,\n",
       "       -0.09972699,  1.6557815 ,  0.47672853, -2.3116539 , -0.81870764,\n",
       "        1.5291704 ,  0.7012389 , -0.4672976 ,  1.288066  ,  0.710435  ,\n",
       "       -0.11292203,  1.4267669 , -0.6820164 ,  0.6083445 ,  1.055769  ,\n",
       "       -0.5711576 , -0.37039667, -0.28657207, -1.8822944 ,  0.9759911 ,\n",
       "       -0.67922527,  0.4210967 , -1.7350934 , -0.30976933, -0.7601396 ,\n",
       "       -1.3016238 ,  1.7906101 ,  0.34431854, -0.10572521, -0.70399797,\n",
       "       -0.9539502 ,  0.47924948, -1.2162089 ,  1.7228553 , -2.9257016 ,\n",
       "       -0.149149  , -2.1084085 ,  0.3484315 , -0.10879481, -1.2686927 ,\n",
       "        0.29086047,  0.96398556,  1.5513694 ,  1.78228   ,  0.5481452 ,\n",
       "        0.6047295 , -0.5654465 , -0.22746079, -0.81418717, -0.07299401,\n",
       "       -1.7093847 , -0.44851175,  0.13161251, -0.37967998, -1.0845933 ,\n",
       "       -0.72299486, -0.73255503,  0.35809386,  1.0446904 , -0.11205904,\n",
       "       -0.673395  , -1.413194  , -0.57811105,  0.5494515 , -0.81408757,\n",
       "       -1.2514725 , -0.8778803 ,  0.48846418,  0.7362381 ,  0.81778204,\n",
       "       -0.130892  ,  0.8464195 , -0.6603786 ,  0.8684398 ,  0.34112933,\n",
       "       -0.86122084,  0.20673664, -0.03342077,  0.4354125 , -0.05748932,\n",
       "       -0.29503033, -0.60410845,  1.3914266 ,  0.32661396,  0.13620296,\n",
       "       -2.2021036 ,  1.5928769 ,  1.4807125 ,  0.04598898,  0.7797658 ,\n",
       "       -0.47189268, -2.3215566 ,  0.47160453, -0.01759874,  0.135782  ,\n",
       "        0.79643524, -0.46251598,  0.59020483,  2.757349  ,  0.34097216,\n",
       "        0.4012092 ,  0.47721595,  2.0163705 , -0.29307497,  0.2587188 ,\n",
       "       -1.1368754 , -1.5844    ,  1.4720846 , -0.41356587,  1.4328673 ,\n",
       "        1.7698482 ,  0.87251604, -0.4787205 , -0.0076864 , -1.4009376 ,\n",
       "        1.3373492 ,  2.5784962 , -1.543101  , -1.616905  , -0.7749599 ,\n",
       "       -1.5999693 ,  0.31791598, -1.353544  , -0.06673147,  0.37070748],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2abe45bda80>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_lg')\n",
    "nlp.pipeline[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.ner.EntityRecognizer at 0x2abe45bda80>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
