{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f99dadb",
   "metadata": {},
   "source": [
    "# Word2Vec: interpretação da linguagem humana com Word embedding\n",
    "\n",
    "Material referente ao curso da Alura disponível [aqui](https://cursos.alura.com.br/course/introducao-word-embedding). O propósito final deste notebook é criar um detector de categoria de notícia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e6123",
   "metadata": {},
   "source": [
    "## Preparando o ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b892113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684db02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1fbe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\salat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f761a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e8e450",
   "metadata": {},
   "source": [
    "## Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "137e99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = pd.read_csv('dados/treino.csv')\n",
    "teste = pd.read_csv('dados/teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3e6962b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Após polêmica, Marine Le Pen diz que abomina n...</td>\n",
       "      <td>A candidata da direita nacionalista à Presidên...</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Macron e Le Pen vão ao 2º turno na França, em ...</td>\n",
       "      <td>O centrista independente Emmanuel Macron e a d...</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apesar de larga vitória nas legislativas, Macr...</td>\n",
       "      <td>As eleições legislativas deste domingo (19) na...</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/06/189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Governo antecipa balanço, e Alckmin anuncia qu...</td>\n",
       "      <td>O número de ocorrências de homicídios dolosos ...</td>\n",
       "      <td>2015-07-24</td>\n",
       "      <td>cotidiano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/cotidiano/2015/07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Após queda em maio, a atividade econômica sobe...</td>\n",
       "      <td>A economia cresceu 0,25% no segundo trimestre,...</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/08/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Após polêmica, Marine Le Pen diz que abomina n...   \n",
       "1  Macron e Le Pen vão ao 2º turno na França, em ...   \n",
       "2  Apesar de larga vitória nas legislativas, Macr...   \n",
       "3  Governo antecipa balanço, e Alckmin anuncia qu...   \n",
       "4  Após queda em maio, a atividade econômica sobe...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  A candidata da direita nacionalista à Presidên...  2017-04-28      mundo   \n",
       "1  O centrista independente Emmanuel Macron e a d...  2017-04-23      mundo   \n",
       "2  As eleições legislativas deste domingo (19) na...  2017-06-19      mundo   \n",
       "3  O número de ocorrências de homicídios dolosos ...  2015-07-24  cotidiano   \n",
       "4  A economia cresceu 0,25% no segundo trimestre,...  2017-08-17    mercado   \n",
       "\n",
       "  subcategory                                               link  \n",
       "0         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
       "1         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
       "2         NaN  http://www1.folha.uol.com.br/mundo/2017/06/189...  \n",
       "3         NaN  http://www1.folha.uol.com.br/cotidiano/2015/07...  \n",
       "4         NaN  http://www1.folha.uol.com.br/mercado/2017/08/1...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "701979df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929606 300\n",
      "\n",
      "</s> -0.001667 -0.000158 -0.000026 0.001300 -0.000796 0.001527 0.000046 0.000584 0.000449 -0.000100 0.000353 0.001251 0.001069 0.000506 0.000574 0.000838 -0.000930 -0.001220 0.000317 0.001315 -0.001120 0.001373 -0.000040 -0.001580 0.000421 -0.000667 -0.001556 -0.000746 0.001604 0.001157 -0.000027 0.000354 0.000358 -0.000527 -0.000573 -0.001512 -0.001557 -0.001637 0.001617 -0.001511 -0.001022 -0.001426 0.001086 -0.001033 0.000593 0.000724 0.000627 -0.000450 -0.001140 0.000333 0.000524 0.001541 0.000284 0.000617 -0.000807 -0.000088 -0.000364 0.001126 -0.001230 -0.001138 -0.001280 0.001330 0.001257 0.000576 0.000764 0.000684 0.001008 -0.000215 -0.000629 -0.001228 -0.001557 -0.000311 -0.000246 0.000045 0.001136 -0.000645 -0.000549 0.001099 0.000858 -0.000886 0.000553 0.000303 0.001433 0.000732 0.001321 -0.000894 -0.000700 -0.000661 -0.001484 -0.000950 -0.001556 -0.000809 0.000348 -0.000068 0.000724 -0.000569 -0.000161 -0.001628 -0.001437 -0.000259 -0.000296 -0.001571 0.000149 0.000847 0.000613 0.000802 0.001507 0.001015 0.000377 0.000255 -0.000458 -0.000777 -0.001561 0.001601 -0.001520 -0.001210 0.000106 0.000714 0.000392 0.001311 -0.001192 -0.000090 -0.001097 0.000424 -0.000954 -0.001272 -0.001178 0.000036 -0.000181 0.000331 -0.001453 -0.001488 -0.001033 -0.000377 0.000257 -0.001418 0.001109 0.000722 0.000936 -0.000113 0.001215 -0.000263 0.000652 0.001190 -0.000258 0.001391 0.001213 0.000783 -0.001202 0.000470 -0.000879 0.000688 -0.001163 -0.001105 0.001497 0.001304 -0.001322 -0.001501 0.001377 0.001439 0.000884 0.000484 0.001239 -0.001578 0.000981 -0.000318 -0.001180 -0.001375 -0.001491 0.001057 -0.001028 0.000893 0.001028 0.000772 0.001636 -0.000331 -0.000247 -0.001006 -0.000329 0.000837 0.000605 -0.000959 0.001410 0.000488 0.001167 -0.000293 -0.001188 -0.000001 0.001135 0.001141 0.001504 0.000198 -0.001060 0.001551 -0.000003 -0.001474 -0.000391 -0.000880 0.000433 -0.000976 -0.001417 0.000563 -0.001188 0.000593 0.001584 -0.001602 -0.000439 -0.001148 -0.001256 0.001185 -0.000738 0.001543 -0.000846 -0.001029 -0.000641 -0.001587 0.001439 -0.001251 0.000942 -0.001414 -0.001106 0.001087 -0.000027 0.000757 -0.000159 -0.001014 -0.000891 0.000024 -0.000238 0.000157 -0.001067 0.000902 -0.001050 -0.000428 -0.001606 -0.000988 0.001391 0.001165 -0.000113 -0.001000 -0.000055 -0.001369 0.000684 0.000715 0.001407 0.000613 0.001389 0.001315 -0.000130 -0.001044 0.000175 -0.000035 0.000959 -0.000345 0.001209 -0.001251 -0.001219 0.001231 -0.000996 -0.001388 0.001038 0.001336 -0.001066 -0.000881 -0.001066 -0.001466 -0.000274 0.000201 0.000401 0.000132 0.000588 0.000589 -0.000128 0.001073 0.001197 0.000109 0.000770 0.001221 0.000996 -0.001174 0.000135 -0.001134 -0.001385 -0.000311 -0.001631 -0.000564 0.001162 -0.000322 -0.000469 0.001312 -0.001402 0.000239 0.000184 0.001300 0.000021 -0.001065 0.000047 -0.000301 0.001336 0.000332\n",
      "\n",
      ", -0.061483 -0.094368 -0.008557 -0.034702 0.021108 -0.011873 -0.041133 -0.095925 0.034668 -0.085286 0.076174 0.003314 0.019222 -0.038695 -0.008963 0.053399 0.162935 0.050372 -0.020163 -0.027230 0.061531 0.060840 0.074610 -0.056173 0.007621 -0.055220 0.018008 0.026096 0.033154 -0.082612 -0.081761 0.164978 -0.034423 0.003094 -0.018217 -0.087445 -0.074446 -0.000142 0.004218 0.036585 0.016095 -0.129141 -0.119698 -0.053717 0.005053 -0.114520 -0.017219 0.023693 -0.024115 0.053125 0.024658 -0.037689 0.012078 0.112701 0.028037 0.047618 -0.024196 0.050112 -0.073095 -0.090859 -0.030613 -0.109599 0.037756 0.063827 0.022537 -0.029640 -0.016311 0.021875 0.064882 0.039002 -0.082970 -0.043166 0.013695 -0.043153 -0.082203 -0.020087 -0.100360 0.007033 -0.074208 -0.067789 -0.024897 -0.020358 0.041731 0.101332 0.020217 -0.032473 0.087827 -0.033611 -0.150526 -0.016615 0.021147 -0.025058 0.097833 0.065067 0.051287 -0.079191 0.089563 -0.008436 -0.038352 0.019787 -0.058452 -0.009696 -0.051077 -0.112245 0.024886 -0.015172 -0.129670 0.068672 0.068483 0.009049 0.007055 -0.032763 0.001527 0.054264 0.029924 -0.023482 0.047470 0.008044 0.014534 0.071155 0.016700 -0.027491 -0.155782 0.039370 0.116605 -0.001262 -0.026638 -0.067078 0.078015 -0.066153 -0.039303 0.009535 -0.055698 -0.022250 0.046948 0.053810 0.038096 0.032157 -0.075257 0.008125 -0.034598 -0.020667 -0.003153 0.032491 -0.031064 0.030744 -0.049023 -0.046149 0.000792 0.010385 -0.057119 -0.122554 0.003210 -0.054363 -0.100899 0.069873 -0.009758 0.055455 0.049243 0.008346 -0.016087 0.093572 0.024125 0.058736 0.037243 -0.007478 0.032175 -0.054205 0.008798 0.032326 0.028384 -0.032259 -0.041842 -0.058281 -0.025145 0.011097 0.023598 -0.033376 0.026204 0.032505 -0.009283 0.041076 0.055565 -0.081757 -0.010077 0.058251 -0.014379 -0.040951 0.006938 -0.004179 0.052006 -0.063725 0.035674 -0.066554 0.030910 -0.004032 0.077445 0.029495 -0.064931 0.040263 -0.055423 -0.021571 0.086767 -0.003583 0.073308 -0.043991 0.022503 -0.028692 -0.063626 -0.048238 0.013439 -0.043673 -0.101352 -0.004321 0.125507 0.088486 0.042756 -0.014497 -0.053445 0.021800 0.038406 -0.034023 -0.074428 -0.132825 0.082152 -0.068497 0.004738 0.047527 -0.073890 0.051089 -0.055886 -0.047786 0.040247 -0.053966 -0.015752 0.099451 0.008218 -0.010716 -0.031540 0.036168 0.054244 0.051809 0.035158 0.043006 -0.027902 0.000130 0.103397 -0.114831 -0.036648 -0.036143 0.024432 0.084740 0.001801 0.044475 -0.035746 -0.024109 0.051210 -0.025769 0.016073 -0.000351 -0.029183 -0.075292 0.042163 0.025010 -0.041439 -0.059192 0.026617 -0.040852 0.034697 0.014691 -0.057382 0.046141 0.070360 0.045274 0.065880 0.011023 -0.031292 -0.015784 -0.023421 -0.042788 0.019669 0.035010 0.036188 -0.058060 -0.093562 0.030321 -0.054753 0.097162 0.001134 0.018939 -0.150218 -0.009928 0.051118 0.105212 -0.055051 -0.047959 -0.136800 -0.003198 0.068969 -0.022456\n",
      "\n",
      "de -0.232068 0.066729 0.103946 -0.072608 0.126237 -0.004782 -0.025139 -0.141489 -0.069438 -0.071078 0.175772 -0.017257 0.094824 0.011020 0.029226 -0.010670 0.144973 0.105333 -0.088273 -0.070952 0.054747 -0.048955 -0.047809 -0.030763 -0.052293 -0.003596 0.078465 0.144430 0.129697 -0.078427 -0.025080 0.212887 0.119806 0.101703 -0.142488 -0.031272 -0.026594 -0.109429 -0.154688 -0.121492 -0.103781 -0.177948 -0.125544 -0.120136 0.031658 0.054160 0.060493 -0.115676 0.132511 -0.001668 -0.125569 -0.124120 0.029025 0.006200 -0.007915 0.058489 0.122710 0.004660 -0.082200 0.123740 0.052747 -0.065657 0.154747 0.155071 0.003547 -0.154675 -0.035110 0.119117 0.080579 0.044262 0.048753 0.054975 -0.064624 -0.046866 0.028242 0.144197 0.029916 -0.024569 0.195781 -0.028608 -0.008233 -0.032542 0.012042 0.011934 -0.068173 0.037028 0.018363 -0.038244 -0.091176 -0.019795 0.051640 -0.008025 -0.025825 -0.001686 -0.069845 -0.039987 0.066244 0.088229 -0.171358 -0.030783 0.082344 0.059267 0.000550 -0.216285 -0.201356 -0.131063 -0.033069 -0.057126 -0.127576 -0.099251 -0.044669 0.035363 -0.119503 -0.090019 -0.006226 -0.000546 0.020731 0.016140 -0.007438 0.032885 -0.161048 0.105681 -0.115705 -0.078013 0.102293 -0.107958 -0.025926 -0.067986 0.017502 -0.054865 -0.007930 -0.006999 -0.000949 -0.026097 0.106295 0.115368 -0.033742 -0.046025 0.009641 -0.065890 0.198822 0.078333 0.062547 0.044947 -0.098424 0.140951 0.109045 -0.004204 -0.174950 0.034234 0.040793 -0.210289 0.104861 0.083616 -0.042511 -0.031439 -0.113108 0.000401 -0.171665 0.097890 0.008065 0.080684 -0.009576 -0.042125 0.177337 -0.005585 -0.004165 0.069755 -0.100323 -0.023289 0.039458 -0.089292 0.069543 -0.009576 0.011562 -0.076654 0.009681 -0.018808 -0.047881 0.026709 -0.021200 -0.032544 0.100362 0.037157 0.005169 -0.001280 -0.064330 -0.049024 -0.002354 0.004443 0.049129 0.026813 0.034249 0.068827 -0.038583 -0.116914 -0.107378 0.046983 0.038218 -0.082186 -0.124208 0.066872 -0.081745 -0.016516 0.016110 0.046844 0.176223 0.083604 -0.086893 -0.114739 -0.159588 0.007700 0.004887 0.006024 -0.020026 0.045816 0.033604 0.054474 0.089348 -0.024353 0.104835 0.084334 0.052662 -0.041422 -0.027877 0.002816 0.150068 -0.052310 0.017154 -0.152326 0.067753 -0.082644 0.119430 -0.012345 0.082965 -0.005791 -0.082770 -0.030068 -0.037331 -0.075347 0.035060 -0.092023 -0.001051 0.012675 0.128757 -0.048579 -0.078527 -0.134126 -0.060009 0.096834 -0.045947 0.132404 -0.030576 -0.006618 -0.088179 -0.124597 -0.095311 -0.086943 0.007010 0.059925 -0.077005 -0.035458 -0.017957 0.081104 0.060141 0.152996 0.083737 -0.025909 0.005420 -0.006300 -0.075839 -0.012399 -0.001624 0.039090 -0.040755 -0.013051 -0.072733 -0.048062 -0.082573 -0.013851 -0.120222 0.011452 -0.083538 0.015996 -0.110800 0.012405 0.045823 0.026705 -0.040789 0.064309 0.007381 -0.037854 0.076050 0.104702 0.010307 -0.103478 0.085227 0.064233 -0.015908 -0.047998\n",
      "\n",
      ". 0.027867 0.077901 -0.054738 -0.095938 -0.010536 0.015269 -0.005752 -0.048440 -0.104021 0.054583 0.050108 0.054979 0.071112 -0.056665 -0.140868 0.203626 0.211330 0.137270 -0.038069 -0.108607 0.060027 0.052436 0.126758 -0.078212 0.008864 -0.028087 0.029884 0.114899 -0.058657 -0.166441 -0.188866 0.294844 -0.147703 -0.095883 -0.104021 -0.097608 -0.172317 0.035795 -0.019025 0.057503 -0.030564 -0.125182 -0.257359 -0.106566 -0.002708 -0.035769 -0.072053 -0.005640 0.016920 0.155101 -0.226088 -0.070904 -0.110280 -0.075773 -0.190123 0.197397 -0.108603 0.155954 0.096544 -0.183301 0.008154 -0.195997 0.035284 -0.025561 0.159142 -0.141005 0.140643 -0.160588 0.140709 0.059974 -0.012396 -0.074953 -0.038325 -0.165941 -0.226005 -0.043738 0.052905 0.085072 -0.165731 0.016894 -0.136569 0.088165 -0.032044 0.022789 0.051207 0.015907 0.093662 0.037576 -0.286139 -0.107587 0.165001 0.095293 0.181427 0.038072 0.078180 -0.116599 0.138464 0.138386 0.020201 -0.028087 0.038829 -0.040074 -0.044944 -0.179895 0.035044 0.090347 -0.036088 0.154828 0.090421 0.172175 -0.127294 0.060227 0.164694 0.141367 0.049326 -0.136940 0.060633 -0.089581 -0.069639 0.043680 0.141455 -0.060588 -0.118859 0.181506 -0.051302 0.165763 0.151366 -0.191232 -0.103888 -0.077344 -0.016534 0.073607 -0.008464 0.216368 0.038251 0.002552 -0.112613 -0.049596 0.018040 -0.032907 -0.131335 -0.049530 0.057485 0.129446 -0.017884 0.075667 -0.061577 -0.015305 0.007649 0.116636 -0.132568 -0.244250 -0.048748 0.003139 -0.123311 0.018462 0.126955 0.079116 -0.067653 0.019126 0.044182 0.037610 0.199809 -0.118487 0.011276 -0.061652 -0.034426 -0.120148 -0.171490 0.009182 0.182921 -0.165212 0.149898 0.062080 -0.129040 0.051808 -0.075070 -0.068688 0.018707 -0.008050 0.108429 -0.111089 0.021230 -0.125982 0.077740 0.140251 -0.051900 0.036107 0.019580 -0.084050 0.065747 0.015718 -0.016900 -0.026964 0.126565 -0.087491 0.069504 0.108362 -0.006355 0.118521 -0.002510 0.060457 0.082848 0.000294 -0.037938 -0.026097 0.084446 0.015568 -0.050540 -0.117080 0.100227 -0.046050 -0.059615 0.086632 0.097266 0.084578 -0.036891 -0.033246 0.021302 -0.149581 -0.006353 -0.035713 -0.177163 -0.016629 -0.028634 -0.147015 -0.017861 0.009931 -0.181849 0.065564 -0.007616 0.094861 0.089787 0.005743 -0.127185 0.093027 -0.107247 -0.019161 -0.201082 -0.008504 0.126500 0.034318 0.011876 0.012696 -0.090981 0.012814 0.038388 -0.274763 -0.123303 -0.073078 0.027702 0.035841 -0.080954 0.091305 0.029009 -0.006000 0.121087 0.016678 -0.070181 -0.080839 -0.016332 -0.081390 -0.059594 0.131390 0.039603 -0.222503 -0.039382 -0.071041 0.267399 -0.010011 -0.077326 -0.044107 0.052901 0.023623 -0.087243 0.011539 -0.006381 -0.074194 -0.041591 -0.061872 -0.098552 -0.094357 -0.062879 -0.150341 -0.087596 0.330078 0.028435 0.087784 0.034434 -0.008122 -0.258485 -0.109828 0.013279 0.043340 0.136803 -0.081573 -0.136733 -0.081884 0.306241 0.093106\n",
      "\n",
      "a -0.019764 -0.096043 -0.010960 0.102012 -0.101848 -0.010257 0.004692 -0.165735 -0.179723 0.067659 0.037108 0.100931 -0.211779 0.163603 -0.042376 -0.021683 -0.014900 0.101581 -0.053583 0.065435 0.126251 0.062320 -0.057445 -0.107130 -0.037044 -0.072958 -0.066655 -0.067962 -0.070879 -0.187941 0.065208 0.102302 -0.024876 0.151433 0.012228 -0.065570 -0.063793 0.015519 0.046230 0.174824 -0.100376 -0.081244 -0.039337 0.017851 0.125168 -0.096404 -0.133070 -0.023451 0.117965 0.005949 0.038928 0.060488 -0.014678 0.024891 -0.001455 0.048539 0.133535 0.084564 0.018362 -0.054294 -0.235691 -0.151528 0.043101 -0.097685 -0.034775 -0.127507 0.010346 -0.010458 0.047631 0.002045 -0.013826 -0.139644 0.128220 -0.020997 -0.057176 0.007458 -0.033133 -0.083235 -0.075585 -0.079414 -0.023531 0.076794 0.051968 0.026857 0.007574 -0.039602 0.027458 -0.146083 0.008662 0.113647 0.007963 0.023413 0.088046 -0.079530 0.027995 -0.017113 -0.056750 0.069447 0.094213 0.123728 0.010051 -0.054795 0.041003 -0.044294 -0.066911 -0.025221 0.059618 0.023494 -0.095354 0.029266 0.047979 0.079102 -0.061757 0.116363 0.011112 0.136784 -0.027020 -0.002793 -0.092629 -0.047217 0.111263 0.102819 0.090932 -0.085343 -0.026490 -0.033315 -0.028970 -0.118673 -0.067360 -0.207183 -0.076011 0.017469 -0.078908 0.031023 0.090820 -0.054443 0.062466 0.065952 -0.028265 0.051329 0.090671 0.106923 0.028011 0.014720 -0.036025 0.099207 -0.013510 -0.147551 -0.077657 -0.099269 0.001171 0.059405 -0.006946 0.123997 0.023131 0.102308 -0.040784 0.027455 -0.181898 0.095958 0.155467 -0.077250 -0.124941 0.058529 0.035851 -0.004447 0.035127 -0.024015 -0.029101 -0.107558 0.055650 -0.017027 0.008997 -0.016504 0.018768 -0.080671 0.029003 0.013937 0.002876 -0.064262 0.001246 0.073494 -0.013986 -0.100303 0.027376 0.030375 -0.177618 0.016413 -0.008711 -0.257308 -0.031904 0.068326 0.038748 0.006762 -0.045245 0.038158 0.093055 -0.069432 -0.140442 -0.030486 -0.097529 0.251017 -0.059000 -0.037363 -0.020030 0.116937 0.018191 -0.005464 0.016485 0.009930 0.007318 -0.131821 -0.005316 -0.063905 0.066936 -0.007235 0.066709 0.153262 -0.087015 -0.196866 0.042973 0.124447 0.034619 -0.021113 0.029881 -0.072679 0.068707 -0.033823 -0.140311 -0.158137 0.215081 -0.020170 -0.062018 -0.038955 0.158768 -0.155656 0.016471 -0.071324 0.069629 -0.070692 0.114725 0.114054 0.154133 -0.143244 -0.082015 -0.070578 0.094558 -0.073491 -0.084676 0.089027 -0.053428 0.034783 0.007488 0.008849 0.137206 -0.061942 -0.155206 -0.022297 -0.054165 0.206418 0.058566 0.033847 0.039555 0.042072 -0.003160 0.350700 -0.067416 -0.089351 0.147734 0.026404 -0.128322 -0.143885 -0.189820 0.162824 -0.038651 -0.045660 0.083507 0.118510 -0.054740 -0.053446 -0.106545 -0.087144 -0.159905 0.006153 0.057539 0.079486 -0.015659 -0.014220 -0.013549 -0.122177 -0.154875 0.319072 -0.251233 0.070468 -0.084041 -0.067580 -0.163386 -0.026553 -0.033245 -0.035199\n",
      "\n",
      "o 0.050016 0.094213 -0.234393 0.057870 -0.255710 -0.099076 0.162541 -0.073166 -0.072231 0.087253 0.154162 -0.021438 0.095246 0.086680 0.027481 0.055959 0.176635 -0.158901 -0.076106 -0.036695 0.115689 -0.039255 -0.116532 -0.143528 0.059030 0.049429 -0.009721 0.204578 -0.020946 -0.254149 -0.167956 0.024087 -0.094412 -0.066287 -0.085987 -0.081115 -0.035314 -0.000736 0.069831 -0.034319 -0.041741 0.007945 0.106777 0.119971 -0.051358 0.152951 -0.109669 0.102599 0.102598 0.044424 -0.088313 0.142374 0.042868 -0.042467 0.199348 -0.234265 -0.044845 -0.109492 0.005783 -0.045873 -0.049017 -0.037446 0.105329 -0.163747 -0.139140 0.153179 -0.117726 -0.113436 0.010813 0.097110 0.074618 0.041083 0.082912 -0.052041 0.009895 0.160828 0.058190 -0.215907 -0.024543 0.042466 -0.011712 0.064930 0.097498 -0.080108 0.019837 -0.059179 0.077248 -0.135312 0.132748 0.069083 0.075949 -0.232743 0.078279 -0.078944 0.116486 0.004099 0.057786 -0.125938 0.068976 0.176170 0.044454 0.085901 0.033849 0.057793 -0.083662 0.061258 -0.037814 0.050392 -0.067302 -0.102103 -0.011153 0.029286 0.032976 0.003400 0.061664 0.076337 -0.097293 0.026432 -0.059397 -0.160978 0.069399 0.307550 0.069981 -0.122410 0.003086 0.027841 0.134213 -0.018279 -0.025608 -0.156602 0.062460 -0.051757 0.030337 -0.042270 0.007516 0.055478 0.075345 0.112685 -0.047181 0.001009 0.031433 -0.134699 -0.034702 -0.082685 -0.182748 -0.097813 0.053774 -0.067876 -0.090774 -0.035145 0.080364 -0.242563 0.024905 -0.012293 0.110051 0.103592 0.138403 -0.035121 0.037955 -0.028042 0.005687 0.042462 0.045434 0.127590 -0.049950 0.079609 -0.152268 -0.102837 -0.083840 -0.132681 -0.073176 0.031672 0.104991 0.082840 0.142188 -0.047643 0.054661 -0.112325 0.006551 0.079335 0.011705 -0.042121 0.086597 0.088994 0.079949 -0.002677 0.106816 -0.055035 0.068153 -0.167192 0.009149 -0.028594 -0.039560 0.001607 -0.122615 0.106024 0.107250 0.050540 -0.043291 0.061397 0.001380 0.054964 0.040893 -0.045046 0.002312 0.032035 -0.026698 -0.042064 0.144622 0.076241 0.024255 -0.086833 0.098275 -0.083894 0.086363 -0.004560 -0.029056 0.126784 0.071785 -0.025692 0.000966 0.100620 0.030299 -0.163968 0.042070 -0.198341 0.099603 -0.113758 0.124685 -0.069966 -0.165131 -0.134782 -0.020419 -0.112747 0.123515 -0.045274 0.167949 -0.109681 -0.146224 0.075453 0.054352 0.023153 -0.062161 -0.059457 -0.124327 0.041855 0.205124 -0.083616 -0.062827 0.017066 0.025000 0.079311 0.018874 -0.055492 -0.129246 0.099183 -0.022749 -0.079510 -0.130005 0.012160 0.060842 0.018816 -0.180103 0.057191 0.018971 0.216519 -0.003726 0.155861 0.112271 0.091379 -0.073707 -0.059254 0.011068 -0.005690 -0.098677 -0.082454 0.105838 0.042144 0.100894 0.096960 -0.228625 0.064737 0.022971 -0.001549 -0.105277 0.149519 -0.055187 0.201671 0.098550 0.056229 -0.107189 -0.005223 -0.077126 0.020865 -0.098107 0.064205 -0.174567 0.196321 0.233813 0.038634\n",
      "\n",
      "e -0.168088 -0.001531 0.017038 -0.137315 -0.026399 -0.018215 0.026076 0.019779 -0.095212 -0.090352 -0.106060 0.061975 -0.000318 -0.002945 0.119734 0.149804 0.108117 0.064784 0.065574 -0.038343 0.159915 -0.006124 -0.038307 -0.094810 -0.019356 -0.045115 -0.121859 0.028930 0.045017 -0.138268 0.099283 0.128659 0.077656 0.032982 -0.086139 0.051552 -0.077685 -0.066857 -0.045233 -0.185625 0.013728 -0.067088 -0.061796 0.091931 0.007931 -0.033784 -0.026604 0.026487 0.002281 0.000939 -0.043053 -0.082718 -0.101476 0.014253 0.106507 0.059285 -0.034097 0.032848 -0.067852 0.103892 0.020742 -0.049702 0.085734 0.069140 -0.036293 -0.001048 -0.043403 -0.033758 -0.041652 -0.049051 -0.070893 -0.002921 0.096254 -0.046406 -0.016074 0.074894 0.098854 -0.015867 -0.024065 0.048818 -0.058226 -0.031364 0.055631 -0.001012 0.002966 0.017624 0.082472 -0.025849 -0.099736 -0.065253 0.002511 0.026550 -0.046750 0.005665 0.058496 -0.068569 0.110588 -0.003354 -0.133236 -0.140404 0.090284 -0.089065 0.010600 -0.143848 0.023044 0.035726 0.044885 -0.081761 0.020406 0.045142 -0.099682 0.013478 -0.102208 -0.048206 0.040736 0.012733 0.064284 0.052800 0.046179 -0.083605 -0.002064 0.003024 0.078588 -0.075731 -0.038192 -0.010662 -0.062210 -0.060302 0.005740 -0.119290 0.049789 -0.009878 0.033791 0.145393 -0.064118 0.005292 -0.046015 -0.012572 -0.002266 0.018877 -0.114718 0.043831 0.036031 -0.077071 0.079499 0.047130 0.136516 -0.029402 -0.095073 -0.198367 0.077792 -0.092858 -0.115212 0.064883 -0.083748 -0.115535 -0.017903 0.080732 0.088457 0.037072 0.044588 0.042071 0.064027 0.035189 0.071027 -0.028330 0.026847 -0.005846 -0.003655 -0.019447 0.057641 -0.057623 0.032575 -0.009248 0.103035 -0.087592 0.049022 -0.030181 0.055313 0.001550 0.136222 -0.081518 -0.003322 -0.196934 -0.125240 -0.039119 0.082201 -0.036932 -0.030666 0.101376 -0.008224 0.045433 0.055995 -0.108370 0.120019 0.024427 -0.055956 0.076503 -0.063588 -0.091926 -0.047620 0.071838 -0.050062 0.122101 0.011679 0.015549 0.060463 -0.174818 0.006131 -0.035602 -0.039755 0.044683 -0.002324 -0.096353 0.153145 -0.181759 0.059133 0.008242 0.009471 0.004472 -0.005789 0.035746 0.107733 0.019606 0.035323 0.013101 0.078772 0.031495 0.011914 0.035316 0.029965 0.010626 0.024444 -0.036373 0.041982 -0.059195 -0.062521 -0.032445 -0.050086 -0.002740 -0.033702 -0.052157 -0.100889 0.010753 -0.017195 0.076872 -0.114096 -0.134334 0.019812 -0.147168 -0.048026 0.055315 -0.021564 0.092953 -0.070098 -0.009133 -0.021408 -0.043442 -0.059603 -0.026196 -0.046402 -0.024446 0.036482 -0.021195 -0.014285 -0.003113 -0.053620 -0.057722 -0.005912 -0.228597 -0.022520 0.008453 -0.131441 0.074053 0.010990 -0.029988 -0.106588 -0.005512 0.036736 -0.002115 -0.078824 -0.067073 0.034071 -0.037642 0.019106 0.080103 0.068267 -0.052487 -0.070635 0.073949 -0.056421 0.017687 0.011800 -0.014045 0.006226 -0.014210 0.088889 -0.007613 -0.042151 0.091935\n",
      "\n",
      "que 0.105677 -0.012054 -0.134709 -0.013888 -0.080373 -0.084105 0.028820 -0.039461 -0.011410 0.033408 -0.031719 0.198935 0.047353 -0.090613 -0.098891 -0.010202 0.144315 0.151674 0.016502 -0.133896 0.031100 -0.007432 -0.059600 0.059022 -0.038658 0.167877 0.082268 0.217249 -0.072088 0.076910 0.079216 -0.037108 0.014821 -0.078732 -0.035230 0.024507 -0.126809 -0.017172 0.040998 -0.043692 -0.149663 -0.049520 0.024513 -0.063125 0.058306 -0.012108 -0.119330 0.034781 -0.102405 0.088640 -0.272843 -0.059915 -0.108119 -0.004685 0.184494 0.029357 -0.012836 0.087409 -0.093633 0.141491 -0.051050 -0.072004 -0.164353 -0.078488 -0.075351 -0.029836 -0.011346 -0.081588 0.032113 -0.120232 -0.028536 0.010188 0.169394 -0.077409 -0.026955 0.083380 0.010644 0.026978 0.131446 -0.055521 -0.142428 -0.164762 0.016372 -0.254786 -0.015511 -0.044090 -0.091434 0.042059 -0.182369 -0.057621 -0.113482 -0.031757 0.036860 0.035760 -0.084302 -0.244284 0.014317 -0.110019 0.076959 -0.003242 0.058425 -0.068168 -0.150191 -0.054872 0.067636 -0.130009 0.033544 -0.028672 -0.029417 -0.003639 0.008028 0.067533 0.015459 0.057868 -0.095344 0.023596 0.005216 -0.068982 0.110498 -0.045724 0.067068 -0.103614 -0.010749 0.079515 -0.160577 -0.037640 -0.090058 0.194754 -0.137685 0.048330 0.023402 -0.080694 -0.076719 0.081176 0.145217 -0.312484 -0.158713 0.003970 0.017241 0.020559 0.019566 -0.020686 0.027909 -0.088033 0.055311 0.114986 0.046477 -0.026289 -0.085503 0.072325 0.033167 -0.027302 0.043202 -0.125175 -0.046430 -0.089749 -0.052517 -0.026923 -0.157140 0.142859 -0.035472 0.053636 -0.015367 -0.041692 0.004743 -0.053162 -0.073490 -0.031711 0.009967 -0.034655 0.209237 -0.052801 0.121190 -0.048079 0.203458 0.037113 -0.095015 0.143972 0.046959 -0.014909 0.169301 -0.034984 0.006088 -0.180444 -0.098740 -0.082224 0.042493 -0.048264 0.034078 -0.155237 0.049812 0.108571 -0.103458 0.015055 -0.005921 -0.020380 -0.059664 0.063496 0.120677 0.028720 0.010933 -0.034094 -0.033195 0.065065 -0.150067 -0.127015 -0.115948 -0.168308 -0.079605 0.112220 -0.024935 0.008233 -0.050985 -0.047235 -0.041944 0.099358 -0.094031 0.008722 -0.044243 0.091927 0.029639 0.053425 -0.020329 -0.007264 0.029055 -0.027748 0.021123 0.023926 -0.068259 -0.034626 0.010976 -0.027882 0.074465 0.017960 -0.142224 0.010472 -0.005171 0.001003 0.031482 0.048073 0.122005 -0.012546 -0.127375 0.137744 -0.043389 -0.067031 -0.028339 -0.102349 -0.001278 -0.075125 -0.209901 0.022713 0.123317 -0.005108 0.206613 -0.119748 0.148568 0.189863 -0.005551 0.042991 0.024824 0.095960 0.049202 -0.115647 -0.075263 -0.101255 0.047671 0.006936 -0.147872 -0.048649 0.152138 0.090100 -0.054797 0.180955 -0.016752 -0.090723 -0.126502 0.137744 0.065590 -0.095213 -0.141592 -0.081258 0.061414 0.138765 -0.047507 0.155577 -0.004058 -0.054305 -0.064755 -0.155780 0.019290 0.092772 -0.113740 0.062508 -0.108115 -0.104516 0.233178 0.085033 -0.063993 0.107476\n",
      "\n",
      "do -0.180377 0.215497 -0.243985 -0.111583 -0.213779 -0.101028 -0.000539 -0.101256 -0.070914 0.038753 0.046168 -0.014838 0.180611 0.000883 0.060867 0.085324 0.226791 -0.021134 -0.137997 -0.202197 0.148571 -0.050565 -0.078147 -0.128638 -0.060884 0.050100 0.018876 0.214215 0.115665 -0.095654 -0.142162 0.120025 -0.097131 0.072397 -0.038019 0.105100 0.071983 -0.160280 -0.051489 -0.098811 -0.117858 -0.034939 -0.009614 0.107021 -0.047199 -0.005264 -0.000139 0.071706 0.161239 -0.161907 -0.337947 0.006058 0.022506 -0.037415 0.171261 -0.062566 -0.062829 -0.086872 0.049601 0.208633 -0.010851 0.096788 0.242130 -0.103836 -0.078473 -0.008937 -0.192728 0.135349 -0.090459 0.275743 0.134895 0.051969 -0.132400 0.040473 -0.095963 0.027610 0.029590 -0.188700 0.164033 0.032661 -0.109406 0.180492 0.147311 0.025806 -0.079043 -0.050046 0.065651 -0.066955 0.037583 -0.031008 0.012122 -0.225802 0.106807 0.067123 0.035571 -0.204494 -0.004813 -0.022719 -0.267100 0.241056 0.115854 0.094971 -0.032575 0.045279 0.030343 -0.103868 0.013372 0.008258 0.027818 -0.051606 0.060680 0.094947 -0.025672 -0.044170 -0.007713 -0.008499 -0.111320 0.112186 -0.091970 -0.085167 0.001894 0.156088 -0.067075 -0.027825 0.093561 0.070251 0.049796 -0.161722 -0.051384 -0.124694 -0.016951 -0.141747 0.002894 -0.133038 -0.015664 0.080839 -0.090980 0.084050 0.089413 0.021215 0.043560 -0.075679 -0.068300 -0.025250 -0.157061 0.022866 0.055717 -0.019705 0.036159 0.183264 0.073571 -0.227341 -0.020978 0.064482 0.075304 0.010691 -0.068159 0.110613 0.047416 -0.029155 -0.043249 -0.074944 0.011065 -0.047526 0.018594 0.114240 -0.265600 0.007173 -0.118795 -0.109128 0.000016 -0.025266 -0.101829 0.167882 0.163892 -0.112688 -0.195755 -0.162868 0.114179 0.149630 0.075342 0.024940 0.099575 0.154626 0.069327 0.046685 0.046306 -0.138379 0.070196 -0.071198 0.028745 0.052231 -0.034552 -0.065006 0.070413 -0.061854 0.102099 0.063467 -0.002194 0.041076 -0.095035 0.138216 0.123084 -0.022177 0.178009 0.171209 0.193143 -0.170747 0.013212 0.020312 -0.129422 0.079598 -0.068529 -0.147807 0.047131 -0.137531 0.091482 0.030125 0.145402 -0.080191 0.025542 0.178609 0.118927 -0.206678 0.094064 -0.042739 -0.084631 -0.076197 0.253984 -0.273463 -0.026424 0.022400 0.012012 0.061563 0.131845 0.000155 -0.068048 -0.138741 -0.137770 0.143289 -0.017924 -0.111125 -0.055598 -0.012842 0.040329 0.034049 0.148260 -0.121714 -0.091318 0.030290 0.127014 0.037068 -0.070445 -0.136299 -0.232076 -0.028718 0.111683 -0.116630 -0.077730 0.033543 -0.032343 0.091454 0.094135 0.163275 0.123356 0.155053 0.137251 0.054886 0.086155 0.132626 -0.112011 0.103465 -0.085405 -0.075092 0.038307 0.075783 0.028715 0.020250 0.078956 0.012173 -0.058316 0.084967 -0.099896 -0.090466 -0.126150 0.144591 0.025099 0.059846 0.102206 0.092871 -0.004201 -0.062104 0.143311 -0.046741 0.010705 -0.065122 -0.074470 0.072302 0.144289 0.067299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('dados/cbow_s300.txt') as f:\n",
    "    for linha in range(10):\n",
    "        print(next(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b0fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = KeyedVectors.load_word2vec_format('dados/cbow_s300.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f043e3b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.49033e-01,  1.26020e-01,  2.17628e-01,  1.82684e-01,\n",
       "        1.65151e-01, -1.59660e-01, -2.34411e-01,  6.00570e-02,\n",
       "        8.03680e-02,  2.87578e-01, -4.81100e-03, -5.68800e-02,\n",
       "        2.15676e-01,  8.65540e-02,  1.25983e-01,  3.36157e-01,\n",
       "       -1.83254e-01, -1.18499e-01,  1.13010e-02,  1.03814e-01,\n",
       "        9.37640e-02,  2.90178e-01, -1.64395e-01, -1.13300e-02,\n",
       "       -1.80676e-01, -1.15820e-02,  1.08728e-01,  1.65898e-01,\n",
       "        9.37900e-02,  2.66767e-01, -1.29890e-02,  9.16030e-02,\n",
       "        2.21292e-01, -1.36497e-01, -4.26350e-02, -1.30038e-01,\n",
       "        2.17067e-01, -1.01963e-01, -3.70960e-02,  1.42155e-01,\n",
       "        3.41109e-01,  2.46560e-01,  1.27458e-01,  5.72360e-02,\n",
       "       -1.47962e-01, -1.60290e-02,  1.86533e-01,  7.71550e-02,\n",
       "       -3.50024e-01, -4.06085e-01,  1.67131e-01, -4.75230e-02,\n",
       "        5.13780e-02, -1.28224e-01,  1.06580e-02, -2.92652e-01,\n",
       "        1.40540e-01, -4.57049e-01,  1.31094e-01,  2.03234e-01,\n",
       "        2.94019e-01,  7.38370e-02,  1.11554e-01, -1.64204e-01,\n",
       "       -3.62020e-02,  1.29522e-01, -1.28321e-01,  1.37502e-01,\n",
       "       -7.99200e-03, -5.07100e-03, -2.86010e-02, -8.99040e-02,\n",
       "        8.82800e-03, -8.27730e-02,  6.91940e-02, -2.70182e-01,\n",
       "        5.47610e-02, -3.06060e-02,  6.89880e-02,  2.38759e-01,\n",
       "       -1.41775e-01,  2.34763e-01, -2.23853e-01, -2.84994e-01,\n",
       "        2.53245e-01,  6.77170e-02, -4.39663e-01, -7.00270e-02,\n",
       "        6.39150e-02, -9.67100e-02, -2.18950e-01, -5.77910e-02,\n",
       "       -1.82689e-01, -3.32202e-01, -7.83070e-02,  7.74620e-02,\n",
       "        8.82920e-02, -4.83618e-01, -1.77812e-01,  5.64040e-02,\n",
       "        1.50339e-01,  8.73000e-02, -1.03121e-01,  1.62065e-01,\n",
       "        4.57940e-02,  9.73590e-02,  1.67230e-02,  3.00791e-01,\n",
       "       -6.49640e-02, -1.95840e-01, -4.33790e-02, -9.46810e-02,\n",
       "        3.73222e-01, -1.65359e-01,  5.58780e-02,  1.72660e-02,\n",
       "       -3.16048e-01,  9.24430e-02, -6.84540e-02, -3.57085e-01,\n",
       "       -1.69469e-01, -1.14090e-01,  9.47230e-02,  3.14999e-01,\n",
       "        2.12717e-01, -2.21540e-02,  1.76870e-02,  1.58473e-01,\n",
       "       -1.39150e-02,  1.23610e-02, -4.13190e-02, -1.47159e-01,\n",
       "       -1.00070e-02,  3.41884e-01,  1.16999e-01, -5.01590e-02,\n",
       "        7.88740e-02,  6.27940e-02,  2.73643e-01,  1.46823e-01,\n",
       "       -1.68857e-01, -1.00014e-01, -5.41060e-02, -3.06130e-02,\n",
       "       -8.85920e-02, -6.19840e-02,  1.21595e-01,  1.13775e-01,\n",
       "        3.97190e-02, -8.54000e-03,  1.05670e-02,  1.12375e-01,\n",
       "        9.70000e-02,  9.05850e-02,  1.25026e-01, -2.92209e-01,\n",
       "        6.81330e-02,  4.06070e-02,  1.33042e-01, -9.77780e-02,\n",
       "       -3.26378e-01,  9.71420e-02, -5.13600e-02,  2.01450e-02,\n",
       "        1.20182e-01, -2.14210e-02, -1.30884e-01,  9.52800e-02,\n",
       "       -5.65320e-02, -8.35370e-02, -2.53035e-01,  9.18650e-02,\n",
       "        7.89190e-02, -6.30710e-02, -1.64057e-01,  8.31660e-02,\n",
       "        1.42698e-01, -2.77053e-01,  7.05810e-02, -1.37800e-02,\n",
       "       -2.74883e-01,  3.02011e-01, -8.34330e-02, -1.14381e-01,\n",
       "       -2.88826e-01,  9.03960e-02,  1.94704e-01, -1.57261e-01,\n",
       "       -2.58910e-02,  1.41321e-01, -1.67231e-01, -2.91540e-02,\n",
       "        8.03650e-02,  1.27378e-01, -1.48120e-01,  2.83291e-01,\n",
       "       -2.65930e-02,  2.15319e-01,  3.35030e-02,  6.47140e-02,\n",
       "        4.20010e-02, -3.85537e-01, -2.67068e-01, -2.77017e-01,\n",
       "       -1.82289e-01, -1.18735e-01, -2.51480e-01, -1.83783e-01,\n",
       "       -2.12362e-01,  2.50214e-01,  3.96240e-02,  2.64830e-02,\n",
       "        1.30810e-01, -1.38478e-01, -1.63040e-02, -2.55850e-02,\n",
       "        2.35141e-01, -8.80540e-02, -9.40650e-02,  1.31790e-01,\n",
       "       -8.33330e-02, -2.40020e-02, -3.38183e-01,  8.10370e-02,\n",
       "       -1.68933e-01,  1.92200e-03,  9.34870e-02,  6.58130e-02,\n",
       "       -1.11925e-01,  1.83907e-01, -6.54900e-03,  4.27730e-02,\n",
       "        3.71566e-01, -3.08570e-02,  1.99647e-01,  1.25516e-01,\n",
       "        1.38471e-01, -9.17400e-02, -2.27814e-01,  8.27690e-02,\n",
       "       -2.94581e-01,  9.56830e-02, -3.48070e-01,  1.02342e-01,\n",
       "       -8.05350e-02,  2.34290e-02, -4.19860e-02,  2.44763e-01,\n",
       "        2.37160e-02, -2.23548e-01, -9.26800e-03, -4.33650e-02,\n",
       "       -1.12413e-01, -4.19178e-01,  1.81267e-01,  1.03648e-01,\n",
       "        2.74945e-01, -9.23560e-02, -4.63300e-02, -2.06314e-01,\n",
       "        4.81410e-02,  2.64603e-01, -1.17113e-01,  1.80097e-01,\n",
       "        5.54220e-02, -1.27460e-01, -1.60328e-01,  1.02289e-01,\n",
       "        4.09530e-02,  1.25305e-01,  1.53398e-01, -2.36950e-02,\n",
       "        2.33967e-01,  2.30250e-02, -1.40227e-01,  3.16349e-01,\n",
       "       -1.99592e-01,  1.25398e-01,  2.72858e-01,  1.09793e-01,\n",
       "       -1.64379e-01,  8.63630e-02,  1.97445e-01, -2.18180e-02,\n",
       "       -1.49784e-01, -3.34461e-01, -4.61000e-04,  1.92640e-02,\n",
       "        2.11149e-01, -2.93349e-01,  5.90160e-02,  1.25044e-01,\n",
       "        7.75570e-02, -2.82863e-01, -3.38890e-02, -9.19950e-02,\n",
       "       -1.43850e-01,  1.45775e-01,  1.04246e-01, -2.60548e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.get_vector('china')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2cdd863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(modelo.get_vector('china'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c4d035",
   "metadata": {},
   "source": [
    "## Testando a vetorização das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ecd709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = [\n",
    "    \"tenha um bom dia\",\n",
    "    \"tenha um péssimo dia\",\n",
    "    \"tenha um ótimo dia\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d35879f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tenha': 3, 'um': 4, 'bom': 0, 'dia': 1, 'péssimo': 2, 'ótimo': 5}\n"
     ]
    }
   ],
   "source": [
    "vetorizador = CountVectorizer()\n",
    "vetorizador.fit(texto)\n",
    "print(vetorizador.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "371811a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vetor_bom = vetorizador.transform([\"bom\"])\n",
    "print(vetor_bom.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a446a1",
   "metadata": {},
   "source": [
    "Esse formato não permite aproximação de palavras por contextualização."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef9c6a2",
   "metadata": {},
   "source": [
    "## Obtendo as palavras mais próximas de outra\n",
    "\n",
    "No caso, utilizando a palavra _china_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d3afbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rússia', 0.7320705652236938),\n",
       " ('índia', 0.7241616249084473),\n",
       " ('tailândia', 0.701935887336731),\n",
       " ('indonésia', 0.6860769987106323),\n",
       " ('turquia', 0.6741336584091187),\n",
       " ('malásia', 0.6665689945220947),\n",
       " ('mongólia', 0.6593616008758545),\n",
       " ('manchúria', 0.6581848859786987),\n",
       " ('urss', 0.6581668853759766),\n",
       " ('grã-bretanha', 0.6568098068237305)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.most_similar('china')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f25531a",
   "metadata": {},
   "source": [
    "## Explorando as relações entre as palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd6641",
   "metadata": {},
   "source": [
    "### Plural\n",
    "\n",
    "_**Nuvens** está para **nuvem** assim como **estrelas** está para **estrela**_\n",
    "\n",
    "$Ns => N : Es => E$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8976c722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('estrelas', 0.5497430562973022),\n",
       " ('plêiades', 0.3791979253292084),\n",
       " ('colinas', 0.3746805489063263),\n",
       " ('trovoadas', 0.37370333075523376),\n",
       " ('sombras', 0.37341946363449097),\n",
       " ('pombas', 0.3726757764816284),\n",
       " ('corredoras', 0.3640727698802948),\n",
       " ('cigarras', 0.36065396666526794),\n",
       " ('galáxias', 0.35754910111427307),\n",
       " ('luas', 0.3575344979763031)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.most_similar(positive=['nuvens', 'estrela'], negative=['nuvem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8546937e",
   "metadata": {},
   "source": [
    "Note que a palavra mais similar é também o plural. Ou seja, operações matemáticas estão permitindo encontrar relações de contexto em um vocabulário. No entanto nem sempre isso funciona corretamente:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f65392",
   "metadata": {},
   "source": [
    "### Gênero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "767baded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enfermeira', 0.6180862188339233),\n",
       " ('psicóloga', 0.47447532415390015),\n",
       " ('dama-de-companhia', 0.47382351756095886),\n",
       " ('esposa', 0.46559131145477295),\n",
       " ('parteira', 0.4636286795139313),\n",
       " ('mãe', 0.45817679166793823),\n",
       " ('governanta', 0.45722925662994385),\n",
       " ('madrasta', 0.4569782614707947),\n",
       " ('menina', 0.4443591237068176),\n",
       " ('filha', 0.4434111416339874)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.most_similar(positive=['médico', 'mulher'], negative=['homem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce733e",
   "metadata": {},
   "source": [
    "Isso é um exemplo de _bias_. As nossas bases de dados refletem os viéses existentes na sociedade. Normalmente _médico_ é associado ao homem e, para mesma região contextual, o mais próximo de mulher é _enfermeira_ e não _médica_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea0fb228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('professora', 0.6192208528518677),\n",
       " ('aluna', 0.5449554324150085),\n",
       " ('esposa', 0.4978230595588684),\n",
       " ('ex-aluna', 0.4884248375892639),\n",
       " ('namorada', 0.4737858474254608),\n",
       " ('enfermeira', 0.4728143811225891),\n",
       " ('filha', 0.4673738479614258),\n",
       " ('irmã', 0.45845916867256165),\n",
       " ('ex-namorada', 0.45824769139289856),\n",
       " ('ex-professora', 0.4510470926761627)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.most_similar(positive=['professor', 'mulher'], negative=['homem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb869bc8",
   "metadata": {},
   "source": [
    "Note como que para o caso de _professor/professora_ o resultado foi correto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf85e45",
   "metadata": {},
   "source": [
    "## Vetorização do texto: Alura News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "120fdd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Daniel Craig será stormtrooper em novo 'Star Wars', diz ator\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino.title.loc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d7b6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizador(texto):\n",
    "    texto = texto.lower()\n",
    "    lista_alfanumerico = []\n",
    "    for token_valido in nltk.word_tokenize(texto):\n",
    "        if(token_valido in string.punctuation): continue\n",
    "        lista_alfanumerico.append(token_valido)\n",
    "    return lista_alfanumerico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "049fcf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'exemplo', '1234']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizador(\"Text exemplo, 1234.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "210bea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinacao_de_vetores_por_soma(palavras_numeros):\n",
    "    vetor_resultante = np.zeros(300)\n",
    "    for pn in palavras_numeros:\n",
    "        try:\n",
    "            vetor_resultante += modelo.get_vector(pn)\n",
    "        except KeyError:\n",
    "            if(pn.isnumeric()):\n",
    "                pn = \"0\" * len(pn)\n",
    "            else:\n",
    "                pn = \"unknown\"\n",
    "            vetor_resultante += modelo.get_vector(pn)\n",
    "    return vetor_resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9a54a20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.82375004e-01,  5.34099996e-01, -9.02680010e-02,  7.14331999e-01,\n",
       "       -3.14585987e-01, -2.63855997e-01,  9.72592972e-01,  2.44773991e-01,\n",
       "       -4.04193003e-01, -2.54065996e-01,  7.71848995e-01,  2.93405998e-01,\n",
       "       -3.74439992e-01,  6.02699012e-01, -8.82209949e-02,  1.79990008e-02,\n",
       "       -1.40151996e+00, -6.86359927e-02, -3.07091993e-01, -5.15361995e-01,\n",
       "       -6.40697980e-01, -7.17419907e-02,  4.17280020e-02,  7.58208998e-01,\n",
       "       -3.10904011e-01,  2.48399377e-03, -6.77058031e-01, -2.58959904e-02,\n",
       "       -2.53299996e-03, -1.92691989e-01,  9.42480136e-02, -3.40558998e-01,\n",
       "        1.07177000e-01,  6.05130000e-02,  1.33777995e-01,  3.31810001e-01,\n",
       "        2.55109005e-01,  7.39010982e-01,  9.77540053e-02,  1.62625000e-01,\n",
       "       -1.29702008e-01,  2.73874013e-01,  2.90505003e-01,  2.74922011e-01,\n",
       "        3.16785989e-01,  2.42439991e-01,  4.11559002e-01,  5.24873011e-01,\n",
       "        1.74969999e-01,  4.76715006e-01,  7.85149941e-02,  6.02812994e-01,\n",
       "        3.25109884e-02,  2.58620996e-01, -1.09545000e-01,  2.04590019e-02,\n",
       "        7.06709959e-02,  5.73083997e-01, -2.48861983e-01, -9.88680013e-02,\n",
       "        1.09175988e-01,  8.47761985e-01,  4.67584983e-01, -6.19500008e-01,\n",
       "        3.06355000e-01,  1.14144992e-01,  5.86097986e-01, -1.80720091e-02,\n",
       "        1.68820992e-01, -5.24729002e-01,  3.36070023e-02, -6.30781017e-01,\n",
       "        2.31687994e-01,  1.03001013e-01, -2.91950993e-01,  3.24900001e-02,\n",
       "       -5.31467006e-01, -2.14082999e-01,  8.12709965e-02, -3.11260002e-01,\n",
       "       -3.20642002e-01, -1.35101996e-01,  5.28911993e-01, -5.42487994e-01,\n",
       "       -1.26109975e-02, -5.01469001e-01, -9.52153988e-01,  4.33777992e-01,\n",
       "        6.48766994e-01, -2.21472986e-01,  1.23723999e-01,  1.25125000e-01,\n",
       "       -2.73977995e-01,  2.65728008e-01,  3.33749995e-01, -1.82669973e-02,\n",
       "        4.09469940e-02, -4.54270039e-02,  1.11200381e-03, -5.46971999e-01,\n",
       "        5.16825993e-01, -2.14767006e-01,  2.59238996e-01, -3.88258994e-01,\n",
       "        1.70420988e-01, -1.35659985e-02,  1.59591004e-01,  4.64730039e-02,\n",
       "       -3.70219007e-01,  1.34514996e-01,  1.46619976e-02,  1.56468997e-01,\n",
       "        6.97276976e-01, -1.87710997e-01,  4.85248994e-01, -2.98350118e-02,\n",
       "       -3.14492974e-01, -1.37867007e-01,  4.06582996e-01, -2.62845978e-01,\n",
       "        2.82382995e-01, -5.19028001e-01,  3.20620000e-01, -2.85983989e-01,\n",
       "        5.18060029e-02, -7.94204012e-01, -5.76514006e-01,  2.48084998e-01,\n",
       "       -5.65011002e-01,  3.32924992e-01,  1.02793999e-01,  2.25717984e-01,\n",
       "        3.17290039e-02,  2.47238998e-01,  3.50322992e-01, -4.53578015e-01,\n",
       "        3.11900996e-01, -1.42954990e-01,  9.55852006e-01,  9.28289890e-02,\n",
       "       -2.74948996e-01,  4.44827989e-01, -8.76098778e-03,  2.36871015e-01,\n",
       "       -2.57340074e-02,  3.62158008e-01, -6.47879913e-02,  1.57090994e-01,\n",
       "        1.08763400e+00, -9.99929931e-02, -1.96892992e-01,  5.77472016e-01,\n",
       "       -2.25724986e-01, -2.32166015e-01, -6.75110072e-02, -2.42720999e-01,\n",
       "        3.85459011e-01,  2.21041005e-01,  4.12907001e-01,  3.72751005e-01,\n",
       "        1.28343001e-01,  1.16153996e-01,  8.98119956e-02, -2.89870001e-01,\n",
       "       -4.37062006e-01,  2.29551993e-01,  3.18188995e-01,  2.90616997e-01,\n",
       "       -1.64168999e-01,  6.25149990e-02, -1.44037999e-01, -1.97280996e-01,\n",
       "        9.52450002e-02,  3.24600050e-02, -2.47274011e-01, -3.81660994e-01,\n",
       "        7.37168983e-01,  2.39933997e-01, -4.65642985e-01, -6.23495001e-01,\n",
       "       -2.17658004e-01, -2.98129916e-02, -3.71471018e-01, -1.60006020e-01,\n",
       "        1.20618023e-01, -3.98766980e-01,  4.45122004e-01,  4.80320081e-02,\n",
       "       -9.08211000e-01,  5.77731982e-01, -2.77169943e-02,  3.22649982e-02,\n",
       "       -3.89346994e-01,  3.23118009e-01,  4.58630063e-02,  8.63368006e-01,\n",
       "       -2.12943986e-01, -5.51183980e-01,  2.32545011e-01, -2.32953995e-01,\n",
       "       -1.88954011e-01, -1.47610013e-01, -1.21894009e-01,  8.24409993e-02,\n",
       "       -4.00086002e-01, -1.53185993e-01, -4.05261990e-01, -3.23181026e-01,\n",
       "        4.02023969e-01,  1.19765396e+00,  1.98752001e-01, -8.35299119e-03,\n",
       "        6.64007012e-01,  1.14772002e-01,  2.10899999e-02, -7.13641000e-01,\n",
       "        3.82603992e-01, -1.99700007e-01, -5.62074014e-01, -3.68900021e-02,\n",
       "       -3.94683000e-01,  1.33081999e-01, -2.05056008e-01, -2.72324987e-01,\n",
       "        6.52464999e-01, -1.93949863e-02, -5.30738980e-01, -1.04357004e-01,\n",
       "       -5.78169972e-02, -1.78456001e-01,  1.72503985e-01, -2.16729995e-01,\n",
       "        2.48613000e-01, -1.40424006e-01, -1.75356001e-01, -2.41229986e-01,\n",
       "       -4.19584001e-01,  2.90922007e-01, -2.83521004e-01, -5.18574003e-01,\n",
       "        1.14870999e-01,  1.72904000e-01,  2.18579997e-01, -3.65467992e-01,\n",
       "        7.24543998e-01,  1.37058001e-01,  2.31927002e-01, -1.27019957e-02,\n",
       "        4.01675995e-01, -2.65149008e-01, -3.02884995e-01,  1.30892001e-01,\n",
       "        4.89474005e-01, -1.09562985e-01,  2.87560020e-02,  5.84154986e-01,\n",
       "        4.79471004e-01,  3.30951989e-01,  5.10529988e-01, -6.98676005e-01,\n",
       "       -4.23729941e-02,  5.71539924e-02,  2.20701013e-01, -1.50165990e-01,\n",
       "       -1.78229000e-01, -5.61244996e-01,  5.30163992e-01,  7.41210030e-02,\n",
       "        4.64967988e-01, -2.34165986e-01,  1.25992016e-01, -4.29813005e-01,\n",
       "        7.06102982e-01,  3.98549005e-01, -2.14484002e-01,  4.33749980e-02,\n",
       "        6.74398996e-01,  1.39131004e-01,  4.97824006e-01, -2.53999978e-03,\n",
       "       -1.30822010e-01, -9.91679952e-02,  3.31339002e-01,  2.14265997e-01,\n",
       "        5.03407001e-01, -3.59017003e-01,  7.28438988e-01, -1.08781600e+00,\n",
       "       -1.10149801e+00, -4.29104989e-01,  6.06817983e-01,  4.84944005e-01,\n",
       "       -1.10501014e-01, -4.70097978e-01,  1.17004007e-01,  5.55853002e-01,\n",
       "        1.08556017e-01, -1.80707007e-01,  4.98199984e-02,  1.35858902e+00])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinacao_de_vetores_por_soma(tokenizador(\"Texto exemplo blateste 123\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4eb01",
   "metadata": {},
   "source": [
    "### Aplicando o tokenizador para treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "059c6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matriz_vetores(textos):\n",
    "    x = len(textos)\n",
    "    matriz = np.zeros((x, 300))\n",
    "    for i in range(x):\n",
    "        tokens = tokenizador(textos.iloc[i])\n",
    "        matriz[i] = combinacao_de_vetores_por_soma(tokens)\n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceb5b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_treino = matriz_vetores(treino.title)\n",
    "matriz_teste = matriz_vetores(teste.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63117cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52357099,  1.00529201,  0.26381801, ...,  0.43726099,\n",
       "         0.187696  ,  0.15216099],\n",
       "       [ 0.34492697,  0.83511301, -0.88874401, ...,  0.19878698,\n",
       "        -1.40402502,  1.49788603],\n",
       "       [ 0.050757  ,  0.95369402,  0.63757797, ...,  0.252318  ,\n",
       "         0.142377  , -1.36338596],\n",
       "       ...,\n",
       "       [-0.89244701,  0.71595099,  0.332483  , ...,  0.40761799,\n",
       "         0.558855  , -0.04226601],\n",
       "       [-0.03248802, -0.259999  , -0.925543  , ..., -0.34076802,\n",
       "        -1.12714999,  0.55980401],\n",
       "       [ 0.46499701,  1.07129601, -0.34205199, ..., -0.83202901,\n",
       "        -0.27768998, -0.34096499]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f53c63",
   "metadata": {},
   "source": [
    "## Aplicando a regressão logística nos vetores encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c770c894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LR = LogisticRegression(solver='saga', max_iter=100, multi_class='multinomial')\n",
    "LR = LogisticRegression(max_iter=200, random_state=SEED)\n",
    "LR.fit(matriz_treino, treino.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0b8ba3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[129]\n"
     ]
    }
   ],
   "source": [
    "print(LR.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7732ca95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7957880368546775"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(matriz_teste, teste.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9413f",
   "metadata": {},
   "source": [
    "Utilizando os parâmetros default (solver `lbfgs`) o algoritimo executou bem mais rápido e com o mesmo score de solvers mais complexos, como o `saga`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8f55115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['colunas', 'esporte', 'mercado', 'cotidiano', 'mundo', 'ilustrada'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste.category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0fcd83",
   "metadata": {},
   "source": [
    "Como ele está se saindo para cada categoria?\n",
    "Verificar o relatório das métricas com `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1699f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_prevista = LR.predict(matriz_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48143e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     colunas       0.86      0.71      0.78      6103\n",
      "   cotidiano       0.61      0.79      0.69      1698\n",
      "     esporte       0.92      0.88      0.90      4663\n",
      "   ilustrada       0.13      0.88      0.23       131\n",
      "     mercado       0.84      0.79      0.81      5867\n",
      "       mundo       0.74      0.86      0.79      2051\n",
      "\n",
      "    accuracy                           0.80     20513\n",
      "   macro avg       0.68      0.82      0.70     20513\n",
      "weighted avg       0.83      0.80      0.81     20513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CR = classification_report(teste.category, label_prevista)\n",
    "print(CR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a11cf7",
   "metadata": {},
   "source": [
    "É semelhante, em alguns aspectos, aos dados para a matriz de confusão.\n",
    "\n",
    "* **Precision (Precisão)**: Do que foi classificado como A, apenas x% é a classificação predita.\n",
    "* **Recall (Revocação)**: De todos os registros que eram da categoria A, x% foram preditos corretamente como A.\n",
    "* **F1-Score**: Média harmônica das métricas anteriores.\n",
    "\n",
    "É notável que a categoria com maior erro é a **ilustrada**. A maior parte do que se classifica como ela foi corretamente classificado, mas boa parte das classificações foi errada. No entanto ela é a cateogoria com menor `support`, ou seja, com menor quantidade de itens (apenas 131) e, portanto, seu impacto não é tão grande na base. Inclusive seu score ruim pode ser justamente pela baixa quantidade de dados.\n",
    "\n",
    "Será que estamos tendo _overfitting_? Vamos comparar o score com os dados de treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3074a49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8166555555555556\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     colunas       0.76      0.72      0.74     15000\n",
      "   cotidiano       0.80      0.81      0.81     15000\n",
      "     esporte       0.90      0.89      0.89     15000\n",
      "   ilustrada       0.83      0.84      0.84     15000\n",
      "     mercado       0.78      0.80      0.79     15000\n",
      "       mundo       0.83      0.85      0.84     15000\n",
      "\n",
      "    accuracy                           0.82     90000\n",
      "   macro avg       0.82      0.82      0.82     90000\n",
      "weighted avg       0.82      0.82      0.82     90000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_prevista = LR.predict(matriz_treino)\n",
    "CR = classification_report(treino.category, label_prevista)\n",
    "print(f'Score: {LR.score(matriz_treino, treino.category)}\\n\\n')\n",
    "print(CR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b4cb74",
   "metadata": {},
   "source": [
    "O Score para treino é maior, mas não tão maior. No entanto é perceptível o desbalanceamento das categorias entre treino e teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40178ea0",
   "metadata": {},
   "source": [
    "### Validando os resultados com o `DummyClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c15d62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.29751864671184125\n",
      "Train Score: 0.16666666666666666\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     colunas       0.30      1.00      0.46      6103\n",
      "   cotidiano       0.00      0.00      0.00      1698\n",
      "     esporte       0.00      0.00      0.00      4663\n",
      "   ilustrada       0.00      0.00      0.00       131\n",
      "     mercado       0.00      0.00      0.00      5867\n",
      "       mundo       0.00      0.00      0.00      2051\n",
      "\n",
      "    accuracy                           0.30     20513\n",
      "   macro avg       0.05      0.17      0.08     20513\n",
      "weighted avg       0.09      0.30      0.14     20513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DC = DummyClassifier(random_state=SEED, strategy='prior')\n",
    "DC.fit(matriz_treino, treino.category)\n",
    "\n",
    "label_prevista_dc = DC.predict(matriz_teste)\n",
    "CR = classification_report(teste.category, label_prevista_dc, zero_division=0)\n",
    "print(f'Test Score: {DC.score(matriz_teste, teste.category)}')\n",
    "print(f'Train Score: {DC.score(matriz_treino, treino.category)}\\n\\n')\n",
    "print(CR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14147c48",
   "metadata": {},
   "source": [
    "No melhor dos casos o `DummyClassifier` tem precisão de 30% ao chutar tudo como \"colunas\". Isso indica que o nosso classificador com acurácia de aproximadamente 80% é bom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379d86e",
   "metadata": {},
   "source": [
    "## Utilizando Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60863e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_sg = KeyedVectors.load_word2vec_format('dados/skip_s300.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1948f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinacao_de_vetores_por_soma_sg(palavras_numeros):\n",
    "    vetor_resultante = np.zeros(300)\n",
    "    for pn in palavras_numeros:\n",
    "        try:\n",
    "            vetor_resultante += modelo_sg.get_vector(pn)\n",
    "        except KeyError:\n",
    "            if(pn.isnumeric()):\n",
    "                pn = \"0\" * len(pn)\n",
    "            else:\n",
    "                pn = \"unknown\"\n",
    "            vetor_resultante += modelo_sg.get_vector(pn)\n",
    "    return vetor_resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b1e5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matriz_vetores_sg(textos):\n",
    "    x = len(textos)\n",
    "    matriz = np.zeros((x, 300))\n",
    "    for i in range(x):\n",
    "        tokens = tokenizador(textos.iloc[i])\n",
    "        matriz[i] = combinacao_de_vetores_por_soma_sg(tokens)\n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "098a5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_treino_sg = matriz_vetores_sg(treino.title)\n",
    "matriz_teste_sg = matriz_vetores_sg(teste.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c04f9d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300, random_state=42)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression(max_iter=300, random_state=SEED)\n",
    "LR.fit(matriz_treino_sg, treino.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3429c589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.8068541900258372\n",
      "Train Score: 0.8314333333333334\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     colunas       0.86      0.72      0.78      6103\n",
      "   cotidiano       0.63      0.81      0.70      1698\n",
      "     esporte       0.93      0.89      0.91      4663\n",
      "   ilustrada       0.15      0.91      0.26       131\n",
      "     mercado       0.84      0.82      0.83      5867\n",
      "       mundo       0.76      0.86      0.80      2051\n",
      "\n",
      "    accuracy                           0.81     20513\n",
      "   macro avg       0.69      0.83      0.71     20513\n",
      "weighted avg       0.84      0.81      0.82     20513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_prevista = LR.predict(matriz_teste_sg)\n",
    "CR = classification_report(teste.category, label_prevista, zero_division=0)\n",
    "print(f'Test Score: {LR.score(matriz_teste_sg, teste.category)}')\n",
    "print(f'Train Score: {LR.score(matriz_treino_sg, treino.category)}\\n\\n')\n",
    "print(CR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a011ea5",
   "metadata": {},
   "source": [
    "Foi necessário aumentar o número de interações, mas foi obtido uma pequena melhora no score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b88db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
